{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import sys\n",
    "import mido\n",
    "from mido import Message, MidiFile, MidiTrack, MAX_PITCHWHEEL, MetaMessage\n",
    "import numpy as np\n",
    "import math\n",
    "from music21 import midi\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # How to program a beat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like everything is music, drumbeats are frequencies. More precisely, is a combination of percussions sounding at different frequencies. While pitch frequency is measured as the frequency of the sound wave in hertz (how many times the air molecules vibrates per second), the frequency in drumbeats is best described as how many times a percussion sounds per minute.  Each percussion can have different frequencies or have the same ones but shifted a bit. \n",
    "\n",
    "Let's define the tempo as 120 beats per minute, or 500,000 microseconds per beat. I know it is weird, but the midi standard usually requires the tempo in microseconds per beat. (Don't worry about this now, but if you are curious, it is calculated by: 60 seconds in a minute * 1000000 microseconds in a second / 120 beats per minute = 500,000 microseconds in a beat)\n",
    "\n",
    "For example, let's look at a simple drum beat where the kick has the same frequency as the snare, but they are shifted by one bar. They both will have half the frequency of the tempo, that is, they will sound every other beat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = MidiFile()\n",
    "\n",
    "track = MidiTrack()\n",
    "outfile.tracks.append(track)\n",
    "\n",
    "\n",
    "track.append(Message('program_change', program=12))\n",
    "\n",
    "tempo = 500000\n",
    "first_frequency = 500000/2\n",
    "second_frequency = 500000/2\n",
    "shift = 480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to convert this to ticks. If they will sound every other beat, and every bit is 480 ticks, they will sound every 960 ticks. \n",
    "\n",
    "However, they will be shifted by one bar, so the difference in ticks between them is = frequency in ticks - shift \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    track.append(Message('note_on', note=36, velocity=100, channel = 9, time=0))\n",
    "    track.append(Message('note_on', note=38, velocity=100, channel = 9 ,time=delta))\n",
    "outfile.save('beat1.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad for a first try! What if we add a snare? And what if we make it interesting by defining its frequency at random, as a frction of the tempo as well as its delta as multiples of a beat (480 ticks)? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we have a problem. We have three different frequencies, so we have to calculate their deltas. As we add more instruments, this gets more and more complicated not so much in the mathematical part, but in the way the midi library is designed, where every sound is added sequentially indicating a delta with respect to the last sound.\n",
    "\n",
    "For this reason, we divide the midi into a track for each percussion.\n",
    "\n",
    "The ratio between the percussion sound and the tempo will be the delta between itself in beats. We just multiply that for 480, the ticks per beat to get the delta in a number that we can feed into the MIDI message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = MidiFile()\n",
    "\n",
    "track.append(MetaMessage('set_tempo',tempo=500000))\n",
    "track.append(Message('program_change', program=12))\n",
    "\n",
    "tempo = 500000\n",
    "first_frequency = 500000/2\n",
    "second_frequency = 500000/2\n",
    "shift = 480\n",
    "\n",
    "track = MidiTrack()\n",
    "outfile.tracks.append(track)\n",
    "track.append(Message('note_on', note=36, velocity=100, channel = 9, time=shift-shift))\n",
    "for i in range(32):\n",
    "    track.append(Message('note_on', note=36, velocity=100, channel = 9, time=2*480))\n",
    "  \n",
    "track1 = MidiTrack()\n",
    "outfile.tracks.append(track1)\n",
    "track1.append(Message('note_on', note=38, velocity=100, channel = 9, time=shift))\n",
    "for i in range(32):\n",
    "    track1.append(Message('note_on', note=38, velocity=100, channel = 9, time=2*480))\n",
    "    \n",
    "hihat_frequency_ratio = random.randint(1,8)\n",
    "hihat_frequency \n",
    "\n",
    "hihat_shift = 480*random.randint(0,4)\n",
    "hihat_shift\n",
    "    \n",
    "  \n",
    "\n",
    "track2 = MidiTrack()\n",
    "outfile.tracks.append(track2)\n",
    "track2.append(Message('note_on', note=42, velocity=100, channel = 9, time=hihat_shift))\n",
    "for i in range(32):\n",
    "    track2.append(Message('note_on', note=42, velocity=100, channel = 9, time=hihat_frequency_ratio*480))\n",
    "\n",
    "outfile.save('beat2.mid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that was very manual. How can we automate that?\n",
    "\n",
    "First, let's define the tempo that we want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000.0"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempo = 100\n",
    "\n",
    "def tempo_to_microseconds(tempo):\n",
    "    return 60*1000000/tempo\n",
    "\n",
    "tempo_ms = tempo_to_microseconds(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an array with percussion options. For now lets just do kick, snare, hi-hat and a bass drum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 = bass drum, 36 = kick = 36, 38 = snare, 42 = hi hat\n",
    "percussion_options = [35,36,38,42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a function that takes how many instruments we want to use and returns a tuple with the number of the instrument, a random frequency and a random shift with regards to the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42, 0.1710376733966058, 0),\n",
       " (38, 1.6425250738088257, 0),\n",
       " (35, 0.35041835277422184, 0),\n",
       " (38, 2.404163634942702, 3),\n",
       " (38, 0.8778434266735691, 1),\n",
       " (42, 1.1187660347410617, 3)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def invent_beat_pattern(percussion_options):\n",
    "    # for now we define from 3 to 8\n",
    "    output = []\n",
    "    selected_options = random.choices(percussion_options,k=random.randint(3,10))\n",
    "    for percussion in selected_options:\n",
    "        frequency_ratio = np.random.random()*np.random.randint(1,2)\n",
    "        shift = np.random.randint(0,4)\n",
    "        output.append((percussion,frequency_ratio,shift))\n",
    "    return output\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instanciate a midifile and set its tempo. We have also created the first track "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = MidiFile()\n",
    "track = MidiTrack()\n",
    "outfile.tracks.append(track)\n",
    "track.append(MetaMessage('set_tempo',tempo=500000))\n",
    "track.append(Message('program_change', program=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fun part, fill our midi file with our pattern!\n",
    "\n",
    "We need to calculate how many sounds are there in 8 bars for each of the selected drum sounds. Since we are taking 8 bars, a common measure for drum patterns, we just need to do a simple proportions rule. For example, is a sound has the same frequency as the tempo, it will sound in every beat. In that case, we would need to add that sound 8 times. However, if the frequency is .5 times that of the tempo, how many times do we have to insert it? Easy, we just multiply .5x8 = 4. We would need to insert it 4 equally spaced times in the 8 bars. If our frequency ratio was .8, we would do .8x8 = 6.4. Since we cannot do 6.4 times, we do six, so we have to take the floor function, with math.floor(). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_insert_time(length, ratio):\n",
    "    '''\n",
    "    Length in bars, ratio as a float.\n",
    "    '''\n",
    "    return length*ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def insert_pattern(pattern, bars, tempo):\n",
    "    midi_file = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "    # Convert tempo to microseconds per beat\n",
    "    tempo_in_micros = int(60*1000000/tempo)\n",
    "    track.append(MetaMessage('set_tempo',tempo=tempo_in_micros))\n",
    "    track.append(Message('program_change', program=12))\n",
    "    '''\n",
    "    Pattern is a list of tuples which contains a midi note, a frequency ratio and a shift.\n",
    "    Bars is the number of bars in the beat. Recommended is 8, but 16 is also cool.\n",
    "    Tempo can be given in BPMs\n",
    "    '''\n",
    "    print('Pattern: ',pattern)\n",
    "\n",
    "    for percussion in pattern:\n",
    "\n",
    "        track = MidiTrack()\n",
    "        midi_file.tracks.append(track)\n",
    "        '''\n",
    "        Calculate the times we are going to insert each one. \n",
    "        In the tuples of percussions and frequencies [0] is the note, [1] is the ratio and [2] is the shift\n",
    "        '''      \n",
    "        times = calculate_insert_time(bars,percussion[1])\n",
    "        print('Times: ', times)\n",
    "        i = 0\n",
    "        while i < times:\n",
    "            print('Delta: ', percussion[2]*480)\n",
    "            track.append(Message('note_on', note=percussion[0], velocity=100, channel = 9, time=percussion[2]*480))\n",
    "            i += 1\n",
    "        \n",
    "    return midi_file\n",
    "            \n",
    "    \n",
    "         \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern:  [(36, 1.3389602552155921, 0), (38, 1.2196631310962898, 3), (42, 0.24273337203199874, 3), (42, 0.6359644504660205, 1), (36, 1.4086847901985302, 0), (42, 0.9162179004233668, 3), (35, 2.8323727514726658, 1), (38, 1.1378768648459472, 3), (35, 0.10231839831024547, 1)]\n",
      "Times:  4.016880765646777\n",
      "Delta:  0\n",
      "Delta:  0\n",
      "Delta:  0\n",
      "Delta:  0\n",
      "Delta:  0\n",
      "Times:  3.658989393288869\n",
      "Delta:  1440\n",
      "Delta:  1440\n",
      "Delta:  1440\n",
      "Delta:  1440\n",
      "Times:  0.7282001160959962\n",
      "Delta:  1440\n",
      "Times:  1.9078933513980614\n",
      "Delta:  480\n",
      "Delta:  480\n",
      "Times:  4.226054370595591\n",
      "Delta:  0\n",
      "Delta:  0\n",
      "Delta:  0\n",
      "Delta:  0\n",
      "Delta:  0\n",
      "Times:  2.7486537012701007\n",
      "Delta:  1440\n",
      "Delta:  1440\n",
      "Delta:  1440\n",
      "Times:  8.497118254417998\n",
      "Delta:  480\n",
      "Delta:  480\n",
      "Delta:  480\n",
      "Delta:  480\n",
      "Delta:  480\n",
      "Delta:  480\n",
      "Delta:  480\n",
      "Delta:  480\n",
      "Delta:  480\n",
      "Times:  3.4136305945378416\n",
      "Delta:  1440\n",
      "Delta:  1440\n",
      "Delta:  1440\n",
      "Delta:  1440\n",
      "Times:  0.3069551949307364\n",
      "Delta:  480\n"
     ]
    }
   ],
   "source": [
    "pattern = invent_beat_pattern(percussion_options)\n",
    "file = insert_pattern(pattern,3,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(36, 1.3389602552155921, 0),\n",
       " (38, 1.2196631310962898, 3),\n",
       " (42, 0.24273337203199874, 3),\n",
       " (42, 0.6359644504660205, 1),\n",
       " (36, 1.4086847901985302, 0),\n",
       " (42, 0.9162179004233668, 3),\n",
       " (35, 2.8323727514726658, 1),\n",
       " (38, 1.1378768648459472, 3),\n",
       " (35, 0.10231839831024547, 1)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.save('beat3.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that beat is terrible. But that was expected, since we just selected everything at random. \n",
    "\n",
    "That opens up a fascinating question. What is pleasurable? Why do some rhtyms feel nice, while others don't? \n",
    "\n",
    "Each beat is a combination of percussions that sound at different and sometimes equal moments. Each different percussion has its own frequency. The relationships between their frequencies are the basis for aesthetic perception. In Western music, note intervals are classified as consonant and dissonant according to the frequency ratios between the played notes. \n",
    "\n",
    "\n",
    "<img width=\"700\" height=\"800\" src='Rationale.jpg'><img>\n",
    "\n",
    "\n",
    "But what is the underlying reason for that? We evolved to obtain information from our environment in order to survive. Seeing is a way of aquiring information, as well as listening, tasting, smelling or touching. If you think about all the things that feel good, they all come from those senses. But why do they feel good? Since our brain is hard wired to seek information from the world for obvious survival advantages (acquiring information of the position of a predator nearby, or the presence of food in an area is very useful), our brain rewards you when you are engaging those senses in a way that they are acquiring the optimal (or close) amount of information. Note that I said optimal and not maximum because more is not necessary better. Too little information is not very helpful and too much is overwhelming, but the brain is able to identify when you are sensing an optimal rate of information and rewards you with pleasure so you keep looking, hearing, eating, smelling or touching whatever the source of information. \n",
    "\n",
    "But the brain not only takes into account the amount of information that you are receiving. It also takes into account how much effort it took for you to obtain it. It rewards you when it costs you an optimal amount of effort: not too much, not too little. So aethetic creation is a matter of balancing amount of information conveyed and amount of effort required from the observer to obtain it. \n",
    "\n",
    "A quick note on what we understand for information. Information can be understood as a measure of randomness. Total randomness has the least amount of information, while determinate things have more. In the context of a beat for example, total randomness would be absolute noise. Our beat was not actually that random, so in fact it can sound worse. We reduced its randomness by selecting which instruments to provide as options, defining the tempo and the shift range of possibilities. A total randomness of sound would carry no information and therefore it would certainly not cause any pleasure, maybe on the contrary, it would feel bad. That's your brain telling you stay away from that source of such uncertainity.\n",
    "\n",
    "On the other hand, we could have a single beat sound. It contains a lot of information, since from all of the universe of quadrillion oportunities for combinations of sounds, we chose a single sound that sounds once. But it is easy to obtain the information from it. Your brain gives you no reward. No need to incentivize laziness. If we repeat that sound over an interval, we are adding a new layer of complexity, with time, because now the brain has to predict when the sound is gonna hit. And that's why you tap your feet, it helps with the prediction. And your brain kinda likes it. But still you can't dance to it. What if we add a snare in between each kick sound. \n",
    "\n",
    "It is a bit better, because now your brain has to predict more different sounds. This is more engaging and your brain rewards that a little more. \n",
    "\n",
    "If we add a third sound, a hi-hat, that sounds in every beat, we add yet more complexity but now this starts to feel like an actual beat you could kinda dance or rap to. But if we start adding instruments like crazy, each sounding at different moments, like those crazy contemprary experimental jazz, your brain will have a tougher time predicting the sounds and will not reward you as much to tell you to stop that effort. \n",
    "\n",
    "How can we estimate that optimal point of effort and information conveyed. Music theory, which was developed through years of iterations, tell us that simpler relationships or ratios between the elements of a piece, be it visual or musical or whatever, are more pleasant. So let's test it. \n",
    "\n",
    "El hecho de que la función de seno, la onda más fundamental, el origen de todas las ondas, tenga una estructura tal que se mida en 4 pasos en el eje de las x y que cada percusión sea lo mismo: una onda en ese eje con cuatro subdivisiones ideales e infinitas no tan ideales. La belleza está en esos puntos.\n",
    "\n",
    "What I would like to be true:\n",
    "\n",
    "Probably all of reality is made up of waves that vibrate in some infinite dimension space and we are just mere pnehomena that arises from the combined vibrations. Beauty brings us closer to some properties within those higher dimension vibrations But currently there is no way to prove it so it remains a hopeful especulation. \n",
    "\n",
    "\n",
    "Complex polyrhythms are closer to random than simple one. Your brain clasifies them as random and produces less dopamine. It is not able to extract information. It is unknown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristics is not all you need (but you do need it)\n",
    "\n",
    "Drum heuristics: \n",
    "\n",
    "The first order heuristic is having this set of rules. The second order is the values for each one. This values can be modified by the user. Also, heuristics are stored inside a list, so they can be changed, removed, added.\n",
    "\n",
    "- Have a set number of necesary intruments\n",
    "- Have a set number of optional instruments\n",
    "- Have a probability for each optional instrument\n",
    "- Limit frequency ratios \n",
    "- Limit shift ratios\n",
    "\n",
    "Hypothesis: \n",
    "\n",
    "Giving agents predefined heuristics and then making them learn from experience generates better melodies than training only. Making models capable of approaching the mean of all songs it was fed with is boring. Giving an agent some initial rules and then let it learn how to use them and even break them is more fun. We will have an agent that composes music. It carries heuristics inside, so we will add that as an attribute. It also has the capacity to learn, so that will be a function. Learning means adjusting the heuristics for now, basically the probability distributions of the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a class that receives a style, tempo. Usually style defines tempo but \n",
    "# for development testing purposes let's pass it\n",
    "\n",
    "class Composer:\n",
    "    \n",
    "    def __init__(self, style, tempo, heuristics):\n",
    "        # the heuristics is a list\n",
    "        self.style = style\n",
    "        self.tempo = tempo\n",
    "        self.heuristics = heuristics\n",
    "        \n",
    "    # for now compose just receives heuristics for drums and melody. They will be functions.\n",
    "    def compose():\n",
    "        return\n",
    "    \n",
    "    def tempo_to_microseconds():\n",
    "        return 60*1000000/self.tempo\n",
    "    \n",
    "\n",
    "\n",
    "def basic_personal_heuristic():\n",
    "    percussion_options = [35,36,38,42]\n",
    "    output = []\n",
    "    return output\n",
    "\n",
    "    \n",
    "def random_pattern_heuristic():\n",
    "# for now we define from 3 to 8\n",
    "    percussion_options = [35,36,38,42]\n",
    "    output = []\n",
    "    selected_options = random.choices(percussion_options,k=random.randint(3,10))\n",
    "    for percussion in selected_options:\n",
    "        frequency_ratio = np.random.random()*np.random.randint(1,2)\n",
    "        shift = np.random.randint(0,4)\n",
    "        output.append((percussion,frequency_ratio,shift))\n",
    "    return output\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def insert_pattern(pattern, bars, tempo):\n",
    "    midi_file = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "    # Convert tempo to microseconds per beat\n",
    "    tempo_in_micros = int(60*1000000/tempo)\n",
    "    track.append(MetaMessage('set_tempo',tempo=tempo_in_micros))\n",
    "    track.append(Message('program_change', program=12))\n",
    "    '''\n",
    "    Pattern is a list of tuples which contains a midi note, a frequency ratio and a shift.\n",
    "    Bars is the number of bars in the beat. Recommended is 8, but 16 is also cool.\n",
    "    Tempo can be given in BPMs\n",
    "    '''\n",
    "    print('Pattern: ',pattern)\n",
    "\n",
    "    for percussion in pattern:\n",
    "\n",
    "        track = MidiTrack()\n",
    "        midi_file.tracks.append(track)\n",
    "        '''\n",
    "        Calculate the times we are going to insert each one. \n",
    "        In the tuples of percussions and frequencies [0] is the note, [1] is the ratio and [2] is the shift\n",
    "        '''      \n",
    "        times = calculate_insert_time(bars,percussion[1])\n",
    "        print('Times: ', times)\n",
    "        i = 0\n",
    "        while i < times:\n",
    "            print('Delta: ', percussion[2]*480)\n",
    "            track.append(Message('note_on', note=percussion[0], velocity=100, channel = 9, time=percussion[2]*480))\n",
    "            i += 1\n",
    "        \n",
    "    return midi_file\n",
    "            \n",
    "    \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melody\n",
    "\n",
    "Melody is just more complicated rhtythm. I wil prove it here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fall_on_beat(midifile):\n",
    "    '''\n",
    "        Function to generate deltas that make notes fall on the beat\n",
    "    ''' \n",
    "    ticks_per_beat = midifile.ticks_per_beat\n",
    "    # Only choose between multiples of the ticks per beat\n",
    "    delta = random.choice([i*ticks_per_beat//4 for i in range(0,4)])\n",
    "    return delta\n",
    "    \n",
    "    \n",
    "\n",
    "def calculate_key(midi_note_number, key_type):\n",
    "    '''\n",
    "    midi_note_number: based on the MIDI standard\n",
    "    key_type options:\n",
    "        major\n",
    "        minor_natural\n",
    "    '''\n",
    "    key = [midi_note_number]\n",
    "    \n",
    "    if key_type.lower() == 'major':\n",
    "        # Major scales are formed by taking the follwing steps = Whole, Whole, Half, Whole, Whole, Whole, Half\n",
    "        # Where whole steps are two semtitones and Half are one semitone. \n",
    "        # Increasing the midi number means an increase of one semitone\n",
    "        steps = ['W','W','H','W','W','W','H']\n",
    "        for i in range(len(steps)):\n",
    "            # If we need to take a whole step, increase by two, otherwise by one\n",
    "            if steps[i] == 'W':\n",
    "                midi_note_number = midi_note_number + 2\n",
    "                key.append(midi_note_number)\n",
    "            else:\n",
    "                midi_note_number = midi_note_number + 1\n",
    "                key.append(midi_note_number)\n",
    "    elif key_type.lower() == 'minor_natural':\n",
    "        # Minor scales are formed by taking the follwing steps = Whole, Whole, Half, Whole, Whole, Whole, Half\n",
    "        # Whole, Half, Whole, Whole, Half, Whole, Whole\n",
    "        steps = ['W','H', 'W', 'W', 'H' ,'W', 'W']\n",
    "        for i in range(len(steps)):\n",
    "            # If we need to take a whole step, increase by two, otherwise by one\n",
    "            if steps[i] == 'W':\n",
    "                midi_note_number = midi_note_number + 2\n",
    "                key.append(midi_note_number)\n",
    "            else:\n",
    "                midi_note_number = midi_note_number + 1\n",
    "                key.append(midi_note_number)     \n",
    "    return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple melody creation\n",
    "\n",
    "MIDI standard\n",
    "\n",
    "A command value of 144 signifies a “note on” event, and 128 typically signifies a “note off” event.\n",
    "Note values are on a range from 0–127, lowest to highest. For example, the lowest note on an 88-key piano has a value of 21, and the highest note is 108. A “middle C” is 60.\n",
    "Velocity values are also given on a range from 0–127 (softest to loudest). The softest possible “note on” velocity is 1.\n",
    "A velocity of 0 is sometimes used in conjunction with a command value of 144 (which typically represents “note on”) to indicate a “note off” message, so it’s helpful to check if the given velocity is 0 as an alternate way of interpreting a “note off” message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_options = ['major','minor natural']\n",
    "key_selec = random.choice(key_options)\n",
    "key = calculate_key(70, key_selec)\n",
    "\n",
    "outfile = MidiFile()\n",
    "track = MidiTrack()\n",
    "outfile.tracks.append(track)\n",
    "\n",
    "track.append(MetaMessage('set_tempo',tempo=500000))\n",
    "\n",
    "track.append(Message('program_change', program=12))\n",
    "\n",
    "for i in range(random.randint(4,12)):\n",
    "    note = random.choice(key)\n",
    "    print(note)\n",
    "    track.append(Message('note_on', note=note, velocity=100, time=fall_on_beat(outfile)))\n",
    "    #track.append(Message('note_off', note=note, velocity=100, time=2*fall_on_beat(outfile)))\n",
    "\n",
    "outfile.save('aver.mid')\n",
    "\n",
    "def playMidi(filename):\n",
    "  mf = midi.MidiFile()\n",
    "  mf.open(filename)\n",
    "  mf.read()\n",
    "  mf.close()\n",
    "  s = midi.translate.midiFileToStream(mf)\n",
    "  s.show('midi')\n",
    "    \n",
    "print(outfile.length)\n",
    "playMidi('aver.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si estas en el primero: toma el que sea. Pasa el intervalo, la nota y el paso (1-8), Dist uniforme\n",
    "\n",
    "En el segundo\n",
    "Si tomaste abajo de 5, mueve normal centro para el siguiente\n",
    "Si tomaste 5 o arriba, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to determine is moving the indicated interval will result in landing on key, either left or right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(note, interval, key_list):\n",
    "    \n",
    "    if (note + interval in key_list):\n",
    "        valid_steps = interval\n",
    "    elif (note - interval in key_list):\n",
    "        valid_steps = (-1)*interval\n",
    "    else:\n",
    "        valid_steps = 0\n",
    "    return valid_steps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we require the midi file because that will be global inside the Composer class\n",
    "def melody_heuristic_normal(midi_file):\n",
    "    # This heuristics plays sequential notes that result from drawing intervals from normal distribution\n",
    "    # centered around middle consonance. All notes played for the same amount of time.\n",
    "    \n",
    "    # create a track\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "    #Select the key of the song, using a random between 2 octaves, 60-83\n",
    "    key_midi = np.random.randint(60,84)\n",
    "    mel_type = random.choice(['major','minor_natural']) \n",
    "    # Compute notes in the key\n",
    "    key = calculate_key(key_midi, mel_type)\n",
    "    # all intervals are selected from a normal distribution of intervals ordered by consonance\n",
    "    # ascending order of consonance as per Malmberg CF. The perception of consonance and dissonance. Psychol Monogr. 1918;25:93–133.\n",
    "    interval_consonance_rank = ['m2','M7','m7','M2','tt','m3','m6','M6','M3','P4','P5','P8']\n",
    "    jumps = [1,11,10,2,6,3,8,9,4,5,7,12]\n",
    "    \n",
    "    # we select a note from the key with a normal distribution centered around the tonic\n",
    "    note_from_key = key[math.floor(abs(np.random.normal(0)))]\n",
    "    \n",
    "    # we will draw intervals from our list with \n",
    "    # \n",
    "    current_note = note_from_key\n",
    "    track.append(Message('note_on', note=current_note, velocity=100, time=480))\n",
    "    for i in range(7):\n",
    "        \n",
    "        print('iteration:quit() ',i)\n",
    "        drawed_interval = jumps[math.floor(abs(np.random.normal(5)))]\n",
    "        \n",
    "        print('current_note drawed interval and key: ',current_note,drawed_interval,key)\n",
    "        valid_steps = 0\n",
    "        while valid_steps == 0:\n",
    "            valid_steps = validate_step(current_note,drawed_interval,key)\n",
    "            if valid_steps != 0:\n",
    "                print('valid steps',valid_steps)   \n",
    "                \n",
    "                current_note = current_note + valid_steps\n",
    "                track.append(Message('note_on', note=current_note, velocity=100, time=480))\n",
    "            else:\n",
    "                drawed_interval = jumps[math.floor(abs(np.random.normal(5)))]\n",
    "                    \n",
    "\n",
    "    return midi_file\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[90, 92, 93, 95, 97, 98, 100, 102]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = abs(np.random.normal(0))\n",
    "\n",
    "calculate_key(90,'minor_natural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "current_note drawed interval and key:  73 2 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps 2\n",
      "iteration:  1\n",
      "current_note drawed interval and key:  75 6 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps 3\n",
      "iteration:  2\n",
      "current_note drawed interval and key:  78 6 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps 6\n",
      "iteration:  3\n",
      "current_note drawed interval and key:  84 6 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps -6\n",
      "iteration:  4\n",
      "current_note drawed interval and key:  78 6 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps 6\n",
      "iteration:  5\n",
      "current_note drawed interval and key:  84 6 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps -6\n",
      "iteration:  6\n",
      "current_note drawed interval and key:  78 3 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps -3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<midi file None type 1, 1 tracks, 8 messages>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfile = MidiFile()\n",
    "melody_heuristic_normal(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile.save('first_heuristic.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, disonant and consonant intervals had a larger probability. Lets try skewing the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we require the midi file because that will be global inside the Composer class\n",
    "def melody_heuristic2(midi_file):\n",
    "    # This heuristics plays sequential notes that result from drawing intervals from normal distribution\n",
    "    # centered around middle consonance. All notes played for the same amount of time.\n",
    "    \n",
    "    # create a track\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "    #Select the key of the song, using a random between 2 octaves, 60-83\n",
    "    key_midi = np.random.randint(60,84)\n",
    "    mel_type = random.choice(['major','minor_natural']) \n",
    "    # Compute notes in the key\n",
    "    key = calculate_key(key_midi, mel_type)\n",
    "    # all intervals are selected from a normal distribution of intervals ordered by consonance\n",
    "    # ascending order of consonance as per Malmberg CF. The perception of consonance and dissonance. Psychol Monogr. 1918;25:93–133.\n",
    "    interval_consonance_rank = ['m2','M7','m7','M2','tt','m3','m6','M6','M3','P4','P5','P8']\n",
    "    jumps = [1,11,10,2,6,3,8,9,4,5,7,12]\n",
    "    \n",
    "    # we select a note from the key with a normal distribution centered around the tonic\n",
    "    note_from_key = key[math.floor(abs(np.random.normal(0)))]\n",
    "    \n",
    "    # we will draw intervals from our list with \n",
    "    # \n",
    "    current_note = note_from_key\n",
    "    track.append(Message('note_on', note=current_note, velocity=100, time=480))\n",
    "    for i in range(7):\n",
    "        \n",
    "        print('iteration: ',i)\n",
    "        drawed_interval = jumps[math.floor(abs(np.random.normal(9)))]\n",
    "        \n",
    "        print('current_note drawed interval and key: ',current_note,drawed_interval,key)\n",
    "        valid_steps = 0\n",
    "        while valid_steps == 0:\n",
    "            valid_steps = validate_step(current_note,drawed_interval,key)\n",
    "            if valid_steps != 0:\n",
    "                print('valid steps',valid_steps)   \n",
    "                \n",
    "                current_note = current_note + valid_steps\n",
    "                track.append(Message('note_on', note=current_note, velocity=100, time=480))\n",
    "            else:\n",
    "                drawed_interval = jumps[math.floor(abs(np.random.normal(5)))]\n",
    "                    \n",
    "\n",
    "    return midi_file\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "current_note drawed interval and key:  72 4 [72, 74, 75, 77, 79, 80, 82, 84]\n",
      "valid steps 2\n",
      "iteration:  1\n",
      "current_note drawed interval and key:  74 9 [72, 74, 75, 77, 79, 80, 82, 84]\n",
      "valid steps 3\n",
      "iteration:  2\n",
      "current_note drawed interval and key:  77 7 [72, 74, 75, 77, 79, 80, 82, 84]\n",
      "valid steps 7\n",
      "iteration:  3\n",
      "current_note drawed interval and key:  84 5 [72, 74, 75, 77, 79, 80, 82, 84]\n",
      "valid steps -5\n",
      "iteration:  4\n",
      "current_note drawed interval and key:  79 9 [72, 74, 75, 77, 79, 80, 82, 84]\n",
      "valid steps -2\n",
      "iteration:  5\n",
      "current_note drawed interval and key:  77 4 [72, 74, 75, 77, 79, 80, 82, 84]\n",
      "valid steps 3\n",
      "iteration:  6\n",
      "current_note drawed interval and key:  80 7 [72, 74, 75, 77, 79, 80, 82, 84]\n",
      "valid steps -6\n"
     ]
    }
   ],
   "source": [
    "file = MidiFile()\n",
    "midi = melody_heuristic2(file)\n",
    "file.save('heuristic2.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "current_note drawed interval and key:  81 4 [79, 81, 83, 84, 86, 88, 90, 91]\n",
      "valid steps 3\n",
      "iteration:  1\n",
      "current_note drawed interval and key:  84 12 [79, 81, 83, 84, 86, 88, 90, 91]\n",
      "valid steps 2\n",
      "iteration:  2\n",
      "current_note drawed interval and key:  86 9 [79, 81, 83, 84, 86, 88, 90, 91]\n",
      "valid steps -3\n",
      "iteration:  3\n",
      "current_note drawed interval and key:  83 5 [79, 81, 83, 84, 86, 88, 90, 91]\n",
      "valid steps 5\n",
      "iteration:  4\n",
      "current_note drawed interval and key:  88 5 [79, 81, 83, 84, 86, 88, 90, 91]\n",
      "valid steps -5\n",
      "iteration:  5\n",
      "current_note drawed interval and key:  83 5 [79, 81, 83, 84, 86, 88, 90, 91]\n",
      "valid steps 5\n",
      "iteration:  6\n",
      "current_note drawed interval and key:  88 4 [79, 81, 83, 84, 86, 88, 90, 91]\n",
      "valid steps -4\n"
     ]
    }
   ],
   "source": [
    "file = MidiFile()\n",
    "midi = melody_heuristic2(file)\n",
    "file.save('heuristic3.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "current_note drawed interval and key:  68 5 [66, 68, 70, 71, 73, 75, 77, 78]\n",
      "valid steps 5\n",
      "iteration:  1\n",
      "current_note drawed interval and key:  73 4 [66, 68, 70, 71, 73, 75, 77, 78]\n",
      "valid steps 4\n",
      "iteration:  2\n",
      "current_note drawed interval and key:  77 4 [66, 68, 70, 71, 73, 75, 77, 78]\n",
      "valid steps -4\n",
      "iteration:  3\n",
      "current_note drawed interval and key:  73 5 [66, 68, 70, 71, 73, 75, 77, 78]\n",
      "valid steps 5\n",
      "iteration:  4\n",
      "current_note drawed interval and key:  78 5 [66, 68, 70, 71, 73, 75, 77, 78]\n",
      "valid steps -5\n",
      "iteration:  5\n",
      "current_note drawed interval and key:  73 7 [66, 68, 70, 71, 73, 75, 77, 78]\n",
      "valid steps -7\n",
      "iteration:  6\n",
      "current_note drawed interval and key:  66 9 [66, 68, 70, 71, 73, 75, 77, 78]\n",
      "valid steps 9\n"
     ]
    }
   ],
   "source": [
    "file = MidiFile()\n",
    "midi = melody_heuristic2(file)\n",
    "file.save('heuristic5.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2RGB(wavelength):\n",
    "    '''\n",
    "    This function converts a wavelength to RGB. We will use this to play with ratios in colors. \n",
    "    '''\n",
    "    w = int(wavelength)\n",
    "\n",
    "    \n",
    "    if w >= 380 and w < 440:\n",
    "        R = -(w - 440.) / (440. - 350.)\n",
    "        G = 0.0\n",
    "        B = 1.0\n",
    "    elif w >= 440 and w < 490:\n",
    "        R = 0.0\n",
    "        G = (w - 440.) / (490. - 440.)\n",
    "        B = 1.0\n",
    "    elif w >= 490 and w < 510:\n",
    "        R = 0.0\n",
    "        G = 1.0\n",
    "        B = -(w - 510.) / (510. - 490.)\n",
    "    elif w >= 510 and w < 580:\n",
    "        R = (w - 510.) / (580. - 510.)\n",
    "        G = 1.0\n",
    "        B = 0.0\n",
    "    elif w >= 580 and w < 645:\n",
    "        R = 1.0\n",
    "        G = -(w - 645.) / (645. - 580.)\n",
    "        B = 0.0\n",
    "    elif w >= 645 and w <= 780:\n",
    "        R = 1.0\n",
    "        G = 0.0\n",
    "        B = 0.0\n",
    "    else:\n",
    "        R = 0.0\n",
    "        G = 0.0\n",
    "        B = 0.0\n",
    "\n",
    "    # intensity correction\n",
    "    if w >= 380 and w < 420:\n",
    "        SSS = 0.3 + 0.7*(w - 350) / (420 - 350)\n",
    "    elif w >= 420 and w <= 700:\n",
    "        SSS = 1.0\n",
    "    elif w > 700 and w <= 780:\n",
    "        SSS = 0.3 + 0.7*(780 - w) / (780 - 700)\n",
    "    else:\n",
    "        SSS = 0.0\n",
    "    SSS *= 255\n",
    "\n",
    "    return [int(SSS*R), int(SSS*G), int(SSS*B)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If note X is consonant with Y, is it because it is similar to its harmonics overtones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomness = all events have same probability -> max amount of information, overwhelming\n",
    "Absolute certainty = one event one probability -> boring, underwhelming\n",
    "\n",
    "Do dissonant notes contain more information? Is there "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4568680/\n",
    "    \n",
    "Most accounts of consonance begin with the interpretation of Greek mathematician and philosopher Pythagoras in the sixth century BCE. According to legend, Pythagoras showed that tones generated by plucked strings whose lengths were related by small integer ratios were pleasing. In light of this observation, the Pythagoreans limited permissible tone combinations to the octave (2:1), the perfect fifth (3:2), and the perfect fourth (4:3), ratios that all had spiritual and cosmological significance in Pythagorean philosophy\n",
    "\n",
    "- The basis for this auditory “roughness” is the physical interaction of sound waves with similar frequencies, whose combination gives rise to alternating periods of constructive and destructive interference. Interference is maximum information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensations of tone\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sensations_of_Tone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cecs.anu.edu.au/people/charles-martin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/pycomposer/\n",
    "    \n",
    "That learns from MIDI file\n",
    "\n",
    "My approach learns from feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative generative music site\n",
    "\n",
    "Add your own heuristics. See how many people like your heuristics. Add your own rules. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent learns what heuristics you like. It is heuristics centered. \n",
    "A GAN can be an heuristic, which was learned. Musicians have both types of heuristics, learned and explicit rule based. That is music theory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristic GAN \n",
    "Have a GAN that generates sequences and discrimintor that evaluates according to the heuristic.\n",
    "generator learns heuristic but not fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate frequency from last step and calculate new frequency from normal distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier series to rhythm and check if it matches simple ratios\n",
    "\n",
    "http://www.thefouriertransform.com/series/fourier.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "How does the brain sound like? Do the frequencies exhibit simple rhythms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create music for focusing and concentrationg\n",
    "\n",
    "We need to find the optimal combination of order and chaos in melody, rhythm and harmony, where order is closer to consonance and chaos to dissonance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
