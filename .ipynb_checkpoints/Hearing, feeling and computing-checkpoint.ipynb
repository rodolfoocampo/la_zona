{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import sys\n",
    "import mido\n",
    "from mido import Message, MidiFile, MidiTrack, MAX_PITCHWHEEL, MetaMessage\n",
    "import numpy as np\n",
    "import math\n",
    "from music21 import midi\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # How to program a beat with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like everything is music, drumbeats are frequencies. More precisely, is a combination of percussions sounding at different frequencies. While pitch frequency is measured as the frequency of the sound wave in hertz (how many times the air molecules vibrates per second), the frequency in drumbeats is best described as how many times a percussion sounds per minute.  Each percussion can have different frequencies or have the same ones but shifted a bit. \n",
    "\n",
    "Let's define the tempo as 120 beats per minute, or 500,000 microseconds per beat. I know it is weird, but the midi standard usually requires the tempo in microseconds per beat. (Don't worry about this now, but if you are curious, it is calculated by: 60 seconds in a minute * 1000000 microseconds in a second / 120 beats per minute = 500,000 microseconds in a beat)\n",
    "\n",
    "For example, let's look at a simple drum beat where the kick has the same frequency as the snare, but they are shifted by one bar. They both will have half the frequency of the tempo, that is, they will sound every other beat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = MidiFile()\n",
    "\n",
    "track = MidiTrack()\n",
    "outfile.tracks.append(track)\n",
    "\n",
    "\n",
    "track.append(Message('program_change', program=12))\n",
    "\n",
    "tempo = 500000\n",
    "first_frequency = 500000/2\n",
    "second_frequency = 500000/2\n",
    "shift = 480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to convert this to ticks. If they will sound every other beat, and every bit is 480 ticks, they will sound every 960 ticks. \n",
    "\n",
    "However, they will be shifted by one bar, so the difference in ticks between them is = frequency in ticks - shift \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    track.append(Message('note_on', note=36, velocity=100, channel = 9, time=0))\n",
    "    track.append(Message('note_on', note=38, velocity=100, channel = 9 ,time=delta))\n",
    "outfile.save('beat1.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad for a first try! What if we add a snare? And what if we make it interesting by defining its frequency at random, as a frction of the tempo as well as its delta as multiples of a beat (480 ticks)? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we have a problem. We have three different frequencies, so we have to calculate their deltas. As we add more instruments, this gets more and more complicated not so much in the mathematical part, but in the way the midi library is designed, where every sound is added sequentially indicating a delta with respect to the last sound.\n",
    "\n",
    "For this reason, we divide the midi into a track for each percussion.\n",
    "\n",
    "The ratio between the percussion sound and the tempo will be the delta between itself in beats. We just multiply that for 480, the ticks per beat to get the delta in a number that we can feed into the MIDI message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = MidiFile()\n",
    "\n",
    "track.append(MetaMessage('set_tempo',tempo=500000))\n",
    "track.append(Message('program_change', program=12))\n",
    "\n",
    "tempo = 500000\n",
    "first_frequency = 500000/2\n",
    "second_frequency = 500000/2\n",
    "shift = 480\n",
    "\n",
    "track = MidiTrack()\n",
    "outfile.tracks.append(track)\n",
    "track.append(Message('note_on', note=36, velocity=100, channel = 9, time=shift-shift))\n",
    "for i in range(32):\n",
    "    track.append(Message('note_on', note=36, velocity=100, channel = 9, time=2*480))\n",
    "  \n",
    "track1 = MidiTrack()\n",
    "outfile.tracks.append(track1)\n",
    "track1.append(Message('note_on', note=38, velocity=100, channel = 9, time=shift))\n",
    "for i in range(32):\n",
    "    track1.append(Message('note_on', note=38, velocity=100, channel = 9, time=2*480))\n",
    "    \n",
    "hihat_frequency_ratio = random.randint(1,8)\n",
    "hihat_frequency \n",
    "\n",
    "hihat_shift = 480*random.randint(0,4)\n",
    "hihat_shift\n",
    "    \n",
    "  \n",
    "\n",
    "track2 = MidiTrack()\n",
    "outfile.tracks.append(track2)\n",
    "track2.append(Message('note_on', note=42, velocity=100, channel = 9, time=hihat_shift))\n",
    "for i in range(32):\n",
    "    track2.append(Message('note_on', note=42, velocity=100, channel = 9, time=hihat_frequency_ratio*480))\n",
    "\n",
    "outfile.save('beat2.mid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that was very manual. How can we automate that?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we create a beat generator?\n",
    "\n",
    "First, let's define the tempo that we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000.0"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempo = 100\n",
    "\n",
    "def tempo_to_microseconds(tempo):\n",
    "    return 60*1000000/tempo\n",
    "\n",
    "tempo_ms = tempo_to_microseconds(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an array with percussion options. For now lets just do kick, snare, hi-hat and a bass drum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 = bass drum, 36 = kick = 36, 38 = snare, 42 = hi hat\n",
    "percussion_options = [35,36,38,42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a function that takes how many instruments we want to use and returns a tuple with the number of the instrument, a random frequency and a random shift with regards to the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42, 0.1710376733966058, 0),\n",
       " (38, 1.6425250738088257, 0),\n",
       " (35, 0.35041835277422184, 0),\n",
       " (38, 2.404163634942702, 3),\n",
       " (38, 0.8778434266735691, 1),\n",
       " (42, 1.1187660347410617, 3)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def invent_beat_pattern(percussion_options):\n",
    "    # for now we define from 3 to 8\n",
    "    output = []\n",
    "    selected_options = random.choices(percussion_options,k=random.randint(3,10))\n",
    "    for percussion in selected_options:\n",
    "        frequency_ratio = np.random.random()*np.random.randint(1,2)\n",
    "        shift = np.random.randint(0,4)\n",
    "        output.append((percussion,frequency_ratio,shift))\n",
    "    return output\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instanciate a midifile and set its tempo. We have also created the first track "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = MidiFile()\n",
    "track = MidiTrack()\n",
    "outfile.tracks.append(track)\n",
    "track.append(MetaMessage('set_tempo',tempo=500000))\n",
    "track.append(Message('program_change', program=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fun part, fill our midi file with our pattern!\n",
    "\n",
    "We need to calculate how many sounds are there in 8 bars for each of the selected drum sounds. Since we are taking 8 bars, a common measure for drum patterns, we just need to do a simple proportions rule. For example, is a sound has the same frequency as the tempo, it will sound in every beat. In that case, we would need to add that sound 8 times. However, if the frequency is .5 times that of the tempo, how many times do we have to insert it? Easy, we just multiply .5x8 = 4. We would need to insert it 4 equally spaced times in the 8 bars. If our frequency ratio was .8, we would do .8x8 = 6.4. Since we cannot do 6.4 times, we do six, so we have to take the floor function, with math.floor(). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_insert_time(length, ratio):\n",
    "    '''\n",
    "    Length in bars, ratio as a float.\n",
    "    '''\n",
    "    return length*ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def insert_pattern(pattern, bars, tempo):\n",
    "    midi_file = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "    # Convert tempo to microseconds per beat\n",
    "    tempo_in_micros = int(60*1000000/tempo)\n",
    "    track.append(MetaMessage('set_tempo',tempo=tempo_in_micros))\n",
    "    track.append(Message('program_change', program=12))\n",
    "    '''\n",
    "    Pattern is a list of tuples which contains a midi note, a frequency ratio and a shift.\n",
    "    Bars is the number of bars in the beat. Recommended is 8, but 16 is also cool.\n",
    "    Tempo can be given in BPMs\n",
    "    '''\n",
    "    print('Pattern: ',pattern)\n",
    "\n",
    "    for percussion in pattern:\n",
    "\n",
    "        track = MidiTrack()\n",
    "        midi_file.tracks.append(track)\n",
    "        '''\n",
    "        Calculate the times we are going to insert each one. \n",
    "        In the tuples of percussions and frequencies [0] is the note, [1] is the ratio and [2] is the shift\n",
    "        '''      \n",
    "        times = calculate_insert_time(bars,percussion[1])\n",
    "        print('Times: ', times)\n",
    "        i = 0\n",
    "        while i < times:\n",
    "            print('Delta: ', percussion[2]*480)\n",
    "            track.append(Message('note_on', note=percussion[0], velocity=100, channel = 9, time=percussion[2]*480))\n",
    "            i += 1\n",
    "        \n",
    "    return midi_file\n",
    "            \n",
    "    \n",
    "         \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = invent_beat_pattern(percussion_options)\n",
    "file = insert_pattern(pattern,3,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(36, 1.3389602552155921, 0),\n",
       " (38, 1.2196631310962898, 3),\n",
       " (42, 0.24273337203199874, 3),\n",
       " (42, 0.6359644504660205, 1),\n",
       " (36, 1.4086847901985302, 0),\n",
       " (42, 0.9162179004233668, 3),\n",
       " (35, 2.8323727514726658, 1),\n",
       " (38, 1.1378768648459472, 3),\n",
       " (35, 0.10231839831024547, 1)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.save('beat3.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that beat is terrible. But that was expected, since we just selected everything at random. \n",
    "\n",
    "That opens up a fascinating question. What is pleasurable? Why do some rhtyms feel nice, while others don't? \n",
    "\n",
    "Each beat is a combination of percussions that sound at different and sometimes equal moments. Each different percussion has its own frequency. The relationships between their frequencies are the basis for aesthetic perception. In Western music, note intervals are classified as consonant and dissonant according to the frequency ratios between the played notes. \n",
    "\n",
    "Simple ratios are easier to understand. Your brain is able to recognize it clearly and is able to predict it. More complex ratios are harder to read by the brain, because it they are harder to predict (it takes more compute power to tell the individual signals apart). A complicated 11/8 jazz drum pattern is much harder to predict to the average person than the simple 4/4 of a hit pop song.\n",
    "\n",
    "When we talk about frequencies in beats, we refer to the the times each percussion sounds in a minute. Another thing that is made of frequency is pitch, or the notes you would hear from a guiter strings. Each note is made up of a characteristic frequency measured in Hertz, much faster than that of drums. That means that if we could play a drum incredibly fast, 440 times a second, we could play an A major. \n",
    "\n",
    "So if they are, at the end of the day, the same thing but at different frequencies, will the preference for simple ratios remain? Yes, as you can see in the following graph.\n",
    "\n",
    "<img width=\"700\" height=\"800\" src='Rationale.jpg'><img>\n",
    "\n",
    "\n",
    "\n",
    "Too little information is not very helpful and too much is overwhelming, but the brain is able to identify when you are sensing an optimal rate of information and rewards you with dopamine so you keep looking, hearing, eating, smelling or touching whatever the source of information. \n",
    "\n",
    "But the brain not only takes into account the amount of information that you are receiving. It also takes into account how much effort it took for you to obtain it. It rewards you when it costs you an optimal amount of effort: not too much, not too little. So aethetic creation is a matter of balancing amount of information conveyed and amount of effort required from the observer to obtain it. \n",
    "\n",
    "\n",
    "It is a bit better, because now your brain has to predict more different sounds. This is more engaging and your brain rewards that a little more. \n",
    "\n",
    "If we add a third sound, a hi-hat, that sounds in every beat, we add yet more complexity but now this starts to feel like an actual beat you could kinda dance or rap to. But if we start adding instruments like crazy, each sounding at different moments, like those crazy contemprary experimental jazz, your brain will have a tougher time predicting the sounds and will not reward you as much to tell you to stop that effort. \n",
    "\n",
    "How can we estimate that optimal point of effort and information conveyed. Music theory, which was developed through years of iterations, tell us that simpler relationships or ratios between the elements of a piece, be it visual or musical or whatever, are more pleasant. So let's test it. \n",
    "\n",
    "El hecho de que la función de seno, la onda más fundamental, el origen de todas las ondas, tenga una estructura tal que se mida en 4 pasos en el eje de las x y que cada percusión sea lo mismo: una onda en ese eje con cuatro subdivisiones ideales e infinitas no tan ideales. La belleza está en esos puntos.\n",
    "\n",
    "What I would like to be true:\n",
    "\n",
    "Probably all of reality is made up of waves that vibrate in some infinite dimension space and we are just mere pnehomena that arises from the combined vibrations. Beauty brings us closer to some properties within those higher dimension vibrations But currently there is no way to prove it so it remains a hopeful especulation. \n",
    "\n",
    "\n",
    "Complex polyrhythms are closer to random than simple one. Your brain clasifies them as random and produces less dopamine. It is not able to extract information. It is unknown. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristics is not all you need (but you do need it)\n",
    "\n",
    "Drum heuristics: \n",
    "\n",
    "The first order heuristic is having this set of rules. The second order is the values for each one. This values can be modified by the user. Also, heuristics are stored inside a list, so they can be changed, removed, added.\n",
    "\n",
    "- Have a set number of necesary intruments\n",
    "- Have a set number of optional instruments\n",
    "- Have a probability for each optional instrument\n",
    "- Limit frequency ratios \n",
    "- Limit shift ratios\n",
    "\n",
    "Hypothesis: \n",
    "\n",
    "Giving agents predefined heuristics and then making them learn from experience generates better melodies than training only. Making models capable of approaching the mean of all songs it was fed with is boring. Giving an agent some initial rules and then let it learn how to use them and even break them is more fun. We will have an agent that composes music. It carries heuristics inside, so we will add that as an attribute. It also has the capacity to learn, so that will be a function. Learning means adjusting the heuristics for now, basically the probability distributions of the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a class that receives a style, tempo. Usually style defines tempo but \n",
    "# for development testing purposes let's pass it\n",
    "\n",
    "class Composer:\n",
    "    \n",
    "    def __init__(self, style, tempo, heuristics):\n",
    "        # the heuristics is a list\n",
    "        self.style = style\n",
    "        self.tempo = tempo\n",
    "        self.heuristics = heuristics\n",
    "        \n",
    "    # for now compose just receives heuristics for drums and melody. They will be functions.\n",
    "    def compose():\n",
    "        return\n",
    "    \n",
    "    def tempo_to_microseconds():\n",
    "        return 60*1000000/self.tempo\n",
    "    \n",
    "\n",
    "\n",
    "def basic_personal_heuristic():\n",
    "    percussion_options = [35,36,38,42]\n",
    "    output = []\n",
    "    return output\n",
    "\n",
    "    \n",
    "def random_pattern_heuristic():\n",
    "# for now we define from 3 to 8\n",
    "    percussion_options = [35,36,38,42]\n",
    "    output = []\n",
    "    selected_options = random.choices(percussion_options,k=random.randint(3,10))\n",
    "    for percussion in selected_options:\n",
    "        frequency_ratio = np.random.random()*np.random.randint(1,2)\n",
    "        shift = np.random.randint(0,4)\n",
    "        output.append((percussion,frequency_ratio,shift))\n",
    "    return output\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def insert_pattern(pattern, bars, tempo):\n",
    "    midi_file = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "    # Convert tempo to microseconds per beat\n",
    "    tempo_in_micros = int(60*1000000/tempo)\n",
    "    track.append(MetaMessage('set_tempo',tempo=tempo_in_micros))\n",
    "    track.append(Message('program_change', program=12))\n",
    "    '''\n",
    "    Pattern is a list of tuples which contains a midi note, a frequency ratio and a shift.\n",
    "    Bars is the number of bars in the beat. Recommended is 8, but 16 is also cool.\n",
    "    Tempo can be given in BPMs\n",
    "    '''\n",
    "    print('Pattern: ',pattern)\n",
    "\n",
    "    for percussion in pattern:\n",
    "\n",
    "        track = MidiTrack()\n",
    "        midi_file.tracks.append(track)\n",
    "        '''\n",
    "        Calculate the times we are going to insert each one. \n",
    "        In the tuples of percussions and frequencies [0] is the note, [1] is the ratio and [2] is the shift\n",
    "        '''      \n",
    "        times = calculate_insert_time(bars,percussion[1])\n",
    "        print('Times: ', times)\n",
    "        i = 0\n",
    "        while i < times:\n",
    "            print('Delta: ', percussion[2]*480)\n",
    "            track.append(Message('note_on', note=percussion[0], velocity=100, channel = 9, time=percussion[2]*480))\n",
    "            i += 1\n",
    "        \n",
    "    return midi_file\n",
    "            \n",
    "    \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melody\n",
    "\n",
    "Melody is just more complicated rhtythm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fall_on_beat(midifile):\n",
    "    '''\n",
    "        Function to generate deltas that make notes fall on the beat\n",
    "    ''' \n",
    "    ticks_per_beat = midifile.ticks_per_beat\n",
    "    # Only choose between multiples of the ticks per beat\n",
    "    delta = random.choice([i*ticks_per_beat//4 for i in range(0,4)])\n",
    "    return delta\n",
    "    \n",
    "    \n",
    "\n",
    "def calculate_key(midi_note_number, key_type):\n",
    "    '''\n",
    "    midi_note_number: based on the MIDI standard\n",
    "    key_type options:\n",
    "        major\n",
    "        minor_natural\n",
    "    '''\n",
    "    key = [midi_note_number]\n",
    "    \n",
    "    if key_type.lower() == 'major':\n",
    "        # Major scales are formed by taking the follwing steps = Whole, Whole, Half, Whole, Whole, Whole, Half\n",
    "        # Where whole steps are two semtitones and Half are one semitone. \n",
    "        # Increasing the midi number means an increase of one semitone\n",
    "        steps = ['W','W','H','W','W','W','H']\n",
    "        for i in range(len(steps)):\n",
    "            # If we need to take a whole step, increase by two, otherwise by one\n",
    "            if steps[i] == 'W':\n",
    "                midi_note_number = midi_note_number + 2\n",
    "                key.append(midi_note_number)\n",
    "            else:\n",
    "                midi_note_number = midi_note_number + 1\n",
    "                key.append(midi_note_number)\n",
    "    elif key_type.lower() == 'minor_natural':\n",
    "        # Minor scales are formed by taking the follwing steps = Whole, Whole, Half, Whole, Whole, Whole, Half\n",
    "        # Whole, Half, Whole, Whole, Half, Whole, Whole\n",
    "        steps = ['W','H', 'W', 'W', 'H' ,'W', 'W']\n",
    "        for i in range(len(steps)):\n",
    "            # If we need to take a whole step, increase by two, otherwise by one\n",
    "            if steps[i] == 'W':\n",
    "                midi_note_number = midi_note_number + 2\n",
    "                key.append(midi_note_number)\n",
    "            else:\n",
    "                midi_note_number = midi_note_number + 1\n",
    "                key.append(midi_note_number)     \n",
    "    return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple melody creation\n",
    "\n",
    "MIDI standard\n",
    "\n",
    "MIDO Library: A command value of 144 signifies a “note on” event, and 128 typically signifies a “note off” event.\n",
    "Note values are on a range from 0–127, lowest to highest. For example, the lowest note on an 88-key piano has a value of 21, and the highest note is 108. A “middle C” is 60.\n",
    "Velocity values are also given on a range from 0–127 (softest to loudest). The softest possible “note on” velocity is 1.\n",
    "A velocity of 0 is sometimes used in conjunction with a command value of 144 (which typically represents “note on”) to indicate a “note off” message, so it’s helpful to check if the given velocity is 0 as an alternate way of interpreting a “note off” message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_options = ['major','minor natural']\n",
    "key_selec = random.choice(key_options)\n",
    "key = calculate_key(70, key_selec)\n",
    "\n",
    "outfile = MidiFile()\n",
    "track = MidiTrack()\n",
    "outfile.tracks.append(track)\n",
    "\n",
    "track.append(MetaMessage('set_tempo',tempo=500000))\n",
    "\n",
    "track.append(Message('program_change', program=12))\n",
    "\n",
    "for i in range(random.randint(4,12)):\n",
    "    note = random.choice(key)\n",
    "    print(note)\n",
    "    track.append(Message('note_on', note=note, velocity=100, time=fall_on_beat(outfile)))\n",
    "    #track.append(Message('note_off', note=note, velocity=100, time=2*fall_on_beat(outfile)))\n",
    "\n",
    "outfile.save('aver.mid')\n",
    "\n",
    "def playMidi(filename):\n",
    "  mf = midi.MidiFile()\n",
    "  mf.open(filename)\n",
    "  mf.read()\n",
    "  mf.close()\n",
    "  s = midi.translate.midiFileToStream(mf)\n",
    "  s.show('midi')\n",
    "    \n",
    "print(outfile.length)\n",
    "playMidi('aver.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si estas en el primero: toma el que sea. Pasa el intervalo, la nota y el paso (1-8), Dist uniforme\n",
    "\n",
    "En el segundo\n",
    "Si tomaste abajo de 5, mueve normal centro para el siguiente\n",
    "Si tomaste 5 o arriba, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to determine is moving the indicated interval will result in landing on key, either left or right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(note, interval, key_list):\n",
    "    \n",
    "    if (note + interval in key_list):\n",
    "        valid_steps = interval\n",
    "    elif (note - interval in key_list):\n",
    "        valid_steps = (-1)*interval\n",
    "    else:\n",
    "        valid_steps = 0\n",
    "    return valid_steps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we require the midi file because that will be global inside the Composer class\n",
    "def melody_heuristic_normal(midi_file):\n",
    "    # This heuristics plays sequential notes that result from drawing intervals from normal distribution\n",
    "    # centered around middle consonance. All notes played for the same amount of time.\n",
    "    \n",
    "    # create a track\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "    #Select the key of the song, using a random between 2 octaves, 60-83\n",
    "    key_midi = np.random.randint(60,84)\n",
    "    mel_type = random.choice(['major','minor_natural']) \n",
    "    # Compute notes in the key\n",
    "    key = calculate_key(key_midi, mel_type)\n",
    "    # all intervals are selected from a normal distribution of intervals ordered by consonance\n",
    "    # ascending order of consonance as per Malmberg CF. The perception of consonance and dissonance. Psychol Monogr. 1918;25:93–133.\n",
    "    interval_consonance_rank = ['m2','M7','m7','M2','tt','m3','m6','M6','M3','P4','P5','P8']\n",
    "    jumps = [1,11,10,2,6,3,8,9,4,5,7,12]\n",
    "    \n",
    "    # we select a note from the key with a normal distribution centered around the tonic\n",
    "    note_from_key = key[math.floor(abs(np.random.normal(0)))]\n",
    "    \n",
    "    # we will draw intervals from our list with \n",
    "    # \n",
    "    current_note = note_from_key\n",
    "    track.append(Message('note_on', note=current_note, velocity=100, time=480))\n",
    "    for i in range(7):\n",
    "        \n",
    "        print('iteration:quit() ',i)\n",
    "        drawed_interval = jumps[math.floor(abs(np.random.normal(5)))]\n",
    "        \n",
    "        print('current_note drawed interval and key: ',current_note,drawed_interval,key)\n",
    "        valid_steps = 0\n",
    "        while valid_steps == 0:\n",
    "            valid_steps = validate_step(current_note,drawed_interval,key)\n",
    "            if valid_steps != 0:\n",
    "                print('valid steps',valid_steps)   \n",
    "                \n",
    "                current_note = current_note + valid_steps\n",
    "                track.append(Message('note_on', note=current_note, velocity=100, time=480))\n",
    "            else:\n",
    "                drawed_interval = jumps[math.floor(abs(np.random.normal(5)))]\n",
    "                    \n",
    "\n",
    "    return midi_file\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[90, 92, 93, 95, 97, 98, 100, 102]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = abs(np.random.normal(0))\n",
    "\n",
    "calculate_key(90,'minor_natural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "current_note drawed interval and key:  73 2 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps 2\n",
      "iteration:  1\n",
      "current_note drawed interval and key:  75 6 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps 3\n",
      "iteration:  2\n",
      "current_note drawed interval and key:  78 6 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps 6\n",
      "iteration:  3\n",
      "current_note drawed interval and key:  84 6 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps -6\n",
      "iteration:  4\n",
      "current_note drawed interval and key:  78 6 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps 6\n",
      "iteration:  5\n",
      "current_note drawed interval and key:  84 6 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps -6\n",
      "iteration:  6\n",
      "current_note drawed interval and key:  78 3 [73, 75, 77, 78, 80, 82, 84, 85]\n",
      "valid steps -3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<midi file None type 1, 1 tracks, 8 messages>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfile = MidiFile()\n",
    "melody_heuristic_normal(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile.save('first_heuristic.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, disonant and consonant intervals had a larger probability. Lets try skewing the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we require the midi file because that will be global inside the Composer class\n",
    "def melody_heuristic2(midi_file):\n",
    "    # This heuristics plays sequential notes that result from drawing intervals from normal distribution\n",
    "    # centered around middle consonance. All notes played for the same amount of time.\n",
    "    \n",
    "    # create a track\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "    #Select the key of the song, using a random between 2 octaves, 60-83\n",
    "    key_midi = np.random.randint(60,84)\n",
    "    mel_type = random.choice(['major','minor_natural']) \n",
    "    # Compute notes in the key\n",
    "    key = calculate_key(key_midi, mel_type)\n",
    "    # all intervals are selected from a normal distribution of intervals ordered by consonance\n",
    "    # ascending order of consonance as per Malmberg CF. The perception of consonance and dissonance. Psychol Monogr. 1918;25:93–133.\n",
    "    interval_consonance_rank = ['m2','M7','m7','M2','tt','m3','m6','M6','M3','P4','P5','P8']\n",
    "    jumps = [1,11,10,2,6,3,8,9,4,5,7,12]\n",
    "    \n",
    "    # we select a note from the key with a normal distribution centered around the tonic\n",
    "    note_from_key = key[math.floor(abs(np.random.normal(0)))]\n",
    "    \n",
    "    # we will draw intervals from our list with \n",
    "    # \n",
    "    current_note = note_from_key\n",
    "    track.append(Message('note_on', note=current_note, velocity=100, time=480))\n",
    "    for i in range(7):\n",
    "        \n",
    "        print('iteration: ',i)\n",
    "        drawed_interval = jumps[math.floor(abs(np.random.normal(9)))]\n",
    "        \n",
    "        print('current_note drawed interval and key: ',current_note,drawed_interval,key)\n",
    "        valid_steps = 0\n",
    "        while valid_steps == 0:\n",
    "            valid_steps = validate_step(current_note,drawed_interval,key)\n",
    "            if valid_steps != 0:\n",
    "                print('valid steps',valid_steps)   \n",
    "                \n",
    "                current_note = current_note + valid_steps\n",
    "                track.append(Message('note_on', note=current_note, velocity=100, time=480))\n",
    "            else:\n",
    "                drawed_interval = jumps[math.floor(abs(np.random.normal(5)))]\n",
    "                    \n",
    "\n",
    "    return midi_file\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = MidiFile()\n",
    "midi = melody_heuristic2(file)\n",
    "file.save('heuristic2.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = MidiFile()\n",
    "midi = melody_heuristic2(file)\n",
    "file.save('heuristic3.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = MidiFile()\n",
    "midi = melody_heuristic2(file)\n",
    "file.save('heuristic5.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2RGB(wavelength):\n",
    "    '''\n",
    "    This function converts a wavelength to RGB. We will use this to play with ratios in colors. \n",
    "    '''\n",
    "    w = int(wavelength)\n",
    "\n",
    "    \n",
    "    if w >= 380 and w < 440:\n",
    "        R = -(w - 440.) / (440. - 350.)\n",
    "        G = 0.0\n",
    "        B = 1.0\n",
    "    elif w >= 440 and w < 490:\n",
    "        R = 0.0\n",
    "        G = (w - 440.) / (490. - 440.)\n",
    "        B = 1.0\n",
    "    elif w >= 490 and w < 510:\n",
    "        R = 0.0\n",
    "        G = 1.0\n",
    "        B = -(w - 510.) / (510. - 490.)\n",
    "    elif w >= 510 and w < 580:\n",
    "        R = (w - 510.) / (580. - 510.)\n",
    "        G = 1.0\n",
    "        B = 0.0\n",
    "    elif w >= 580 and w < 645:\n",
    "        R = 1.0\n",
    "        G = -(w - 645.) / (645. - 580.)\n",
    "        B = 0.0\n",
    "    elif w >= 645 and w <= 780:\n",
    "        R = 1.0\n",
    "        G = 0.0\n",
    "        B = 0.0\n",
    "    else:\n",
    "        R = 0.0\n",
    "        G = 0.0\n",
    "        B = 0.0\n",
    "\n",
    "    # intensity correction\n",
    "    if w >= 380 and w < 420:\n",
    "        SSS = 0.3 + 0.7*(w - 350) / (420 - 350)\n",
    "    elif w >= 420 and w <= 700:\n",
    "        SSS = 1.0\n",
    "    elif w > 700 and w <= 780:\n",
    "        SSS = 0.3 + 0.7*(780 - w) / (780 - 700)\n",
    "    else:\n",
    "        SSS = 0.0\n",
    "    SSS *= 255\n",
    "\n",
    "    return [int(SSS*R), int(SSS*G), int(SSS*B)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self notes:\n",
    "\n",
    "If note X is consonant with Y, is it because it is similar to its harmonics overtones?\n",
    "\n",
    "Randomness = all events have same probability -> max amount of information, overwhelming\n",
    "\n",
    "Absolute certainty = one event one probability -> boring, underwhelming\n",
    "\n",
    "Do dissonant intervals contain more information? \n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4568680/\n",
    "    \n",
    "Most accounts of consonance begin with the interpretation of Greek mathematician and philosopher Pythagoras in the sixth century BCE. According to legend, Pythagoras showed that tones generated by plucked strings whose lengths were related by small integer ratios were pleasing. In light of this observation, the Pythagoreans limited permissible tone combinations to the octave (2:1), the perfect fifth (3:2), and the perfect fourth (4:3), ratios that all had spiritual and cosmological significance in Pythagorean philosophy\n",
    "\n",
    "- The basis for this auditory “roughness” is the physical interaction of sound waves with similar frequencies, whose combination gives rise to alternating periods of constructive and destructive interference. Interference is maximum information\n",
    "\n",
    "Sensations of tone\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sensations_of_Tone\n",
    "\n",
    "https://cecs.anu.edu.au/people/charles-martin\n",
    "\n",
    "https://pypi.org/project/pycomposer/\n",
    "    \n",
    "That learns from MIDI file\n",
    "\n",
    "My approach learns from feedback\n",
    "\n",
    "\n",
    "\n",
    "Collaborative generative music site\n",
    "\n",
    "Add your own heuristics. See how many people like your heuristics. Add your own rules. \n",
    "\n",
    "The agent learns what heuristics you like. It is heuristics centered. \n",
    "A GAN can be an heuristic, which was learned. Musicians have both types of heuristics, learned and explicit rule based. That is music theory. \n",
    "\n",
    "Heuristic GAN \n",
    "Have a GAN that generates sequences and discrimintor that evaluates according to the heuristic.\n",
    "generator learns heuristic but not fixed\n",
    "\n",
    "Calculate frequency from last step and calculate new frequency from normal distribution\n",
    "\n",
    "\n",
    "\n",
    "Fourier series to rhythm and check if it matches simple ratios\n",
    "\n",
    "http://www.thefouriertransform.com/series/fourier.php\n",
    "\n",
    "How does the brain sound like? Do the frequencies exhibit simple rhythms?\n",
    "\n",
    "> How to create music for focusing and concentrationg\n",
    "\n",
    "We need to find the optimal combination of order and chaos in melody, rhythm and harmony, where order is closer to consonance and chaos to dissonance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
